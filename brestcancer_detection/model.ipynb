{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T05:33:38.455599Z",
     "start_time": "2024-09-27T05:33:38.410911Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn.functional import relu\n",
    "# Load the model file\n",
    "model_weights = torch.load(r'C:\\Users\\arsha\\PycharmProjects\\DSU\\brestcancer_detection\\breast_cancer_diagnosis.pt', map_location=torch.device('cpu'),weights_only=True)\n",
    "\n",
    "# Check if it's a state_dict (weights only)\n",
    "if isinstance(model_weights, dict):\n",
    "    # If it contains keys like \"conv1.weight\", \"fc.bias\", it's likely a state dict\n",
    "    print(\"This file contains only weights (state_dict).\")\n",
    "    for key, value in model_weights.items():\n",
    "        print(key, value.shape)\n",
    "else:\n",
    "    print(\"This file contains the entire model.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains only weights (state_dict).\n",
      "conv1.weight torch.Size([6, 3, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.bias torch.Size([16])\n",
      "fc1.weight torch.Size([64, 400])\n",
      "fc1.bias torch.Size([64])\n",
      "fc2.weight torch.Size([1, 64])\n",
      "fc2.bias torch.Size([1])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T05:34:00.186280Z",
     "start_time": "2024-09-27T05:33:38.469955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class BreastCancerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BreastCancerModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(5, 5))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d(output_size=(5, 5))\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(relu(self.conv1(x)))\n",
    "        x = self.pool2(relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Load the model and weights\n",
    "model = BreastCancerModel()\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\arsha\\PycharmProjects\\DSU\\brestcancer_detection\\breast_cancer_diagnosis.pt', map_location=torch.device('cpu'),weights_only=True), strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128 or your preferred size\n",
    "    transforms.ToTensor()             # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Define the paths to your image folders\n",
    "image_folders = {\n",
    "    'normal': r'C:\\Users\\arsha\\PycharmProjects\\DSU\\brestcancer_detection\\normal',\n",
    "    'benign': r\"C:\\Users\\arsha\\PycharmProjects\\DSU\\brestcancer_detection\\benign\",\n",
    "    'malignant': r'C:\\Users\\arsha\\PycharmProjects\\DSU\\brestcancer_detection\\malignant'\n",
    "}\n",
    "\n",
    "images = []\n",
    "labels = []  # To store labels corresponding to images\n",
    "\n",
    "# Loop through each folder and load images and labels\n",
    "for label, folder in enumerate(image_folders.values()):\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            image = Image.open(img_path).convert('RGB')  # Ensure it's in RGB format\n",
    "            image = transform(image)  # Apply transformations\n",
    "            \n",
    "            images.append(image)  # Append the image to the list\n",
    "            \n",
    "            # Assign label based on folder\n",
    "            if label == 0:  # Normal\n",
    "                labels.append(0)  # No cancer\n",
    "            elif label == 1:  # Benign\n",
    "                labels.append(1)  # or 1 if you consider benign as cancerous\n",
    "            elif label == 2:  # Malignant\n",
    "                labels.append(1)  # Positive for cancer\n",
    "\n",
    "# Convert lists to tensors\n",
    "input_images= torch.stack(images)  \n",
    "input_labels = torch.tensor(labels, dtype=torch.float32)  # Shape: [N]\n",
    "\n",
    "# Check shapes for debugging\n",
    "print(f'Images tensor shape: {input_images.shape}')\n",
    "print(f'Labels tensor shape: {input_labels.shape}')\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_images)\n",
    "    predictions = (outputs > 0.5).float()\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = (predictions.squeeze() == input_labels).sum().item()\n",
    "total_predictions = input_labels.size(0)\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ],
   "id": "6cb2efa08c1c2303",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images tensor shape: torch.Size([1578, 3, 128, 128])\n",
      "Labels tensor shape: torch.Size([1578])\n",
      "Accuracy: 50+16.86%\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T05:34:00.398852Z",
     "start_time": "2024-09-27T05:34:00.391655Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a786b9a0b786692",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
